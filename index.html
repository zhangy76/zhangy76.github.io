<html>

<head>
  <title>Yufei Zhang - Homepage</title>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-D41DLSC2BJ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-D41DLSC2BJ');
  </script>

  <style type="text/css" media="screen">
    html,
    body,
    div,
    span,
    applet,
    object,
    iframe,
    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    p,
    blockquote,
    pre,
    a,
    abbr,
    acronym,
    address,
    big,
    cite,
    code,
    del,
    dfn,
    em,
    font,
    img,
    ins,
    kbd,
    q,
    s,
    samp,
    small,
    strike,
    strong,
    sub,
    tt,
    var,
    dl,
    dt,
    dd,
    ol,
    ul,
    li,
    fieldset,
    form,
    label,
    legend,
    table,
    caption,
    tbody,
    tfoot,
    thead,
    tr,
    th,
    td {
      border: 0pt none;
      font-family: inherit;
      font-size: 100%;
      font-style: inherit;
      font-weight: inherit;
      margin: 0pt;
      outline-color: invert;
      outline-style: none;
      outline-width: 0pt;
      padding: 0pt;
      vertical-align: baseline;
    }

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }

    a.paper {
      font-weight: bold;
      font-size: 12pt;
    }

    b.paper {
      font-weight: bold;
      font-size: 12pt;
    }

    * {
      margin: 0pt;
      padding: 0pt;
    }

    body {
      position: relative;
      margin: 3em auto 2em auto;
      width: 1080px;
      font-family: Lato, Verdana, Helvetica, sans-serif;
      font-size: 14px;
      background: #eee;
    }

    h2 {
      font-family: Lato, Verdana, Helvetica, sans-serif;
      font-size: 16pt;
      font-weight: 700;
    }

    h4 {
      font-family: Lato, Verdana, Helvetica, sans-serif;
      font-size: 13pt;
      font-weight: 700;
    }

    h3 {
      font-family: Lato, Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700;
    }

    strong {
      font-family: Lato, Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }

    ul {
      list-style: circle;
    }

    img {
      border: none;
    }

    li {
      padding-bottom: 0.5em;
      margin-left: 1.4em;
    }

    strong,
    b {
      font-weight: bold;
    }

    em,
    i {
      font-style: italic;
    }

    div.section {
      clear: both;
      margin-bottom: 2em;
      background: #eee;
    }

    div.spanner {
      clear: both;
    }

    div.paper {
      clear: both;
      margin-top: 0.3em;
      margin-bottom: 0.3em;
      border: 1px solid #ddd;
      background: #fff;
      padding: 1em 1em 1em 1em;
    }

    div.paper div {
      padding-left: 230px;
    }

    div.paper div.wide {
      padding-right: 0px;
    }

    img.paper {
      margin-bottom: 0.5em;
      float: left;
      width: 200px;
    }

    span.blurb {
      font-style: italic;
      display: block;
      margin-top: 0.75em;
      margin-bottom: 0.5em;
    }

    pre,
    code {
      font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
      margin: 1em 0;
      padding: 0;
    }

    div.paper pre {
      font-size: 0.9em;
    }
  </style>

  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-7953909-1']);
    _gaq.push(['_trackPageview']);

    (function () {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>

  <link href="./page_files/css" rel="stylesheet" type="text/css">
  <style id="style-1-cropbar-clipper">
    /* Copyright 2014 Evernote Corporation. All rights reserved. */
    .en-markup-crop-options {
      top: 18px !important;
      left: 50% !important;
      margin-left: -100px !important;
      width: 200px !important;
      border: 2px rgba(255, 255, 255, .38) solid !important;
      border-radius: 4px !important;
    }

    .en-markup-crop-options div div:first-of-type {
      margin-left: 0px !important;
    }
  </style>
</head>

<body>

  <div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 250px;">
    <div style="margin: 0 auto; width: 100%; line-height: 100%;">
      <img title="YufeiZhang" style="float: right; padding-right: 2.0em; margin-left: 1em; height: 250px;" src="figures/Yufei_PhD.jpeg" />
      <div style="padding-left: 2em; vertical-align: top; height: 250px;">
        <div style="padding-left: 22em; margin-bottom: 1em">
        <span style="font-size: 18pt; line-height: 250%; font-weight:bold">Yufei Zhang</span> 
        </div>
        <div style="padding-left: 0; margin-bottom: 1em;">
          I am Member of Technical Staff at <a href="https://myolab.ai/">MyoLab AI</a>.
        </div>
        <div style="padding-left: 0; margin-bottom: 1em">
          I received my Ph.D. from <a href="https://www.rpi.edu/" target="_blank">Rensselaer Polytechnic Institute</a>, where I was supervised by <a href="https://www.ecse.rpi.edu/~qji/" target="_blank">Prof. Qiang Ji</a>.  
          Previously, I obtained my M.S. from <a href="https://www.rochester.edu/" target="_blank">University of Rochester</a> and B.E. from <a href="https://en.xjtu.edu.cn/" target="_blank">Xi'an Jiaotong University</a>. 
          I worked as a Research Scientist Intern at <a href="https://www.meta.com/research/" target="_blank">Meta Reality Labs</a> in 2024 and <a href="https://aws.amazon.com/one/" target="_blank">Amazon One (AWS)</a> in 2022.
        </div>
        <div style="padding-left: 0; margin-bottom: 1em"> 
          My research aims to build <strong>Human-Embodied AI</strong> capable of perceiving, understanding, and simulating human behavior. 
          It integrates <strong>Physics</strong> (e.g., biomechanics) and <strong>Probabilistic Modeling</strong> (e.g., uncertainty estimation) into scalable data-driven systems. 
        </div>
        <div style="padding-left: 2em; margin-top: 2em"></div>
        <a href="https://github.com/zhangy76" target="_blank">GitHub</a> |
        <a href="https://www.linkedin.com/in/yufei-zhang-4b7b69152" target="_blank">Linkedin</a> |
        <a href="https://scholar.google.com/citations?user=gtVCkSgAAAAJ&hl=en" target="_blank">Google Scholar</a> |
        <a href="https://twitter.com/YufeiZhang0000" target="_blank">Twitter</a>
        </div>
    </div>
  </div>

    <div class="section">
      <h2 id="reports " style="margin-left: 2em;">Selected Publications</h2>

      <div class="paper" id="VideoHand">
        <img title="VideoHand" style="float: left; padding-left: 0.0em; padding-right: .0em; width: 360px; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.2);" src="./figures/VideoHand.png" />
        <div style="position: relative; left: 2em; top: 1em;"> 
          <strong>Diffusion-based 3D Hand Motion Recovery with Intuitive Physics</strong> <br /> 
          <br />
          <span style="line-height: 200%;">
          <span style="font-weight: bold; color: #bd0000;">Yufei Zhang</span>, Zijun Cui, Jeffrey O. Kephart, Qiang Ji <br />
          <em>ICCV, 2025</em> <br />
          <a href="https://zhangy76.github.io/" target="_blank"> Paper </a> | 
          <a href="https://zhangy76.github.io/" target="_blank"> SupMat </a> | 
          <a href="https://zhangy76.github.io/" target="_blank"> Code </a> (coming soon)
          </span><br />
        </div>
        <div class="spanner"></div>
      </div>

      <div class="paper" id="ImageHand">
        <img title="ImageHand" style="float: left; padding-left: 0.0em; padding-right: .0em; width: 360px; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.2);" src="./figures/ImageHand.png" />
        <div style="position: relative; left: 2em; top: 1em;"> 
          <strong>Weakly-Supervised 3D Hand Reconstruction with Knowledge Prior and Uncertainty Guidance</strong> <br /> 
          <br />
          <span style="line-height: 200%;">
          <span style="font-weight: bold; color: #bd0000;">Yufei Zhang</span>, Jeffrey O. Kephart, Qiang Ji <br />
          <em>ECCV, 2024</em> <br />
          <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/10017.pdf" target="_blank"> Paper </a> | 
          <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/10017-supp.pdf" target="_blank"> SupMat </a> | 
          <a href="https://github.com/zhangy76/KNOWN-Hand" target="_blank"> Code </a>
          </span><br />
        </div>
        <div class="spanner"></div>
      </div>

      <div class="paper" id="PhysPT">
        <img title="PhysPT" style="float: left; padding-left: 0.0em; padding-right: .0em; width: 360px; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.2);" src="./figures/PhysPT.png" />
        <div style="position: relative; left: 2em; top: 1em; margin-right: 2em;">
          <strong>PhysPT: Physics-aware Pretrained Transformer for Estimating Human Dynamics from Monocular Videos</strong> <br /> 
          <br />
          <span style="line-height: 200%;">
          <span style="font-weight: bold; color: #bd0000;">Yufei Zhang</span>, Jeffrey O. Kephart, Zijun Cui, Qiang Ji <br />
          <em>CVPR, 2024</em> <br />
          <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_PhysPT_Physics-aware_Pretrained_Transformer_for_Estimating_Human_Dynamics_from_Monocular_CVPR_2024_paper.pdf" target="_blank"> Paper </a> | 
          <a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Zhang_PhysPT_Physics-aware_Pretrained_CVPR_2024_supplemental.pdf" target="_blank"> SupMat </a> | 
          <a href="https://github.com/zhangy76/PhysPT" target="_blank"> Code </a> 
          </span><br />
        </div>
        <div class="spanner"></div>
      </div>

      <div class="paper" id="PhysMoP">
        <img title="PhysMoP" style="float: left; padding-left: 0.0em; padding-right: .0em; width: 360px; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.2);", src="./figures/PhysMoP.png" />
        <div style="position: relative; left: 2em; top: 1em; margin-right: 2em;">
          <strong>Incorporating Physics Principles for Precise Human Motion Prediction</strong> <br /> 
          <br />
          <span style="line-height: 200%;"> 
          <span style="font-weight: bold; color: #bd0000;">Yufei Zhang</span>, Jeffrey O. Kephart, Qiang Ji <br />
          <em>WACV, 2024</em> <br />
          <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_Incorporating_Physics_Principles_for_Precise_Human_Motion_Prediction_WACV_2024_paper.pdf" target="_blank"> Paper </a> | 
          <a href="https://openaccess.thecvf.com/content/WACV2024/supplemental/Zhang_Incorporating_Physics_Principles_WACV_2024_supplemental.pdf" target="_blank"> SupMat </a> | 
          <a href="https://github.com/zhangy76/PhysMoP" target="_blank"> Code </a> 
          </span><br />
        </div>
        <div class="spanner"></div>
      </div>

      <div class="paper" id="KNOWN">
        <img title="KNOWN" style="float: left; padding-left: 0.0em; padding-right: .0em; width: 360px; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.2);", src="./figures/KNOWN.png" />
        <div style="position: relative; left: 2em; top: 1em; margin-right: 2em;">
          <strong>Body Knowledge and Uncertainty Modeling for Monocular 3D Human Body Reconstruction</strong> <br />
          <br />
          <span style="line-height: 200%;"> 
          <span style="font-weight: bold; color: #bd0000;">Yufei Zhang</span>, Hanjing Wang, Jeffrey O. Kephart, Qiang Ji <br />
          <em>ICCV, 2023</em> <br />
          <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Body_Knowledge_and_Uncertainty_Modeling_for_Monocular_3D_Human_Body_ICCV_2023_paper.pdf" target="_blank"> Paper </a> | 
          <a href="https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Body_Knowledge_and_ICCV_2023_supplemental.pdf" target="_blank"> SupMat </a> | 
          <a href="https://github.com/zhangy76/KNOWN" target="_blank"> Code </a> 
          </span><br />
        </div>
        <div class="spanner"></div>
      </div>

      <div class="paper" id="RPF">
        <img title="RPF" style="float: left; padding-left: 0.0em; padding-right: .0em; width: 360px; box-shadow: 4px 4px 10px rgba(0, 0, 0, 0.2);", src="./figures/RPF.png" />
        <div style="position: relative; left: 2em; top: 1em; margin-right: 2em;">
          <strong>Robust Partial Fingerprint Recognition</strong> <br /> 
          <br />
          <span style="line-height: 200%;">
          <span style="font-weight: bold; color: #bd0000;">Yufei Zhang</span>, Rui Zhao, Ziyi Zhao, Naveen Ramakrishnan, Manoj Aggarwal, Gerard Medioni, Qiang Ji <br />
          <em>CVPR Biometrics Workshop, 2023</em> <br />
          <a href="https://openaccess.thecvf.com/content/CVPR2023W/Biometrics/papers/Zhang_Robust_Partial_Fingerprint_Recognition_CVPRW_2023_paper.pdf" target="_blank"> Paper </a> | 
          <a href="https://openaccess.thecvf.com/content/CVPR2023W/Biometrics/supplemental/Zhang_Robust_Partial_Fingerprint_CVPRW_2023_supplemental.pdf" target="_blank"> SupMat </a>
          </span><br />
        </div>
        <div class="spanner"></div>
      </div>
    </div>
    <div class="section">
      <h2 id="reports" style="margin-left: 2em;">Projects</h2>
      <div class="paper" id="projects">
        <li><strong>High-fidelity Hand Motion Generation and Retargeting</strong> <br />
        Research Scientist Intern at <span style="font-weight: bold;">Meta Reality Labs</span>, 2024 Summer<br />
        Mentor: Priyamvad Deshmukh. </li>
        <li><strong>Robust Biometrics Identification under Occlusion</strong> <br />
        Research Scientist Intern at <span style="font-weight: bold;">Amazon One (AWS)</span>, 2022 Summer<br />
        Mentor: Rui Zhao, Ziyi Zhao. </li>
        <li><strong>Environment-driven Conceptual Learning </strong> <br />
          Research Assistant, <span style="font-weight: bold;">Boston Fusion Company</span>, 2023 Summer <br />
          </li>
        <li><strong>Vision-based Automatic Surgery Performance Evaluation </strong> <br />
          Research Assistant, <span style="font-weight: bold;">DEVCOM Army Research Laboratory</span>, 2021.1-2021.12 <br />
          Advisor: Prof. Qiang Ji, Prof. Suvranu De. </li>
        <li><strong>Audio Signal Processing & Music Information Retrieval</strong> <br />
          Research Assistant, <span style="font-weight: bold;">Audio Information Research Lab</span>, 2018.5-2018.9 <br />
          Advisor: Prof. Zhiyao Duan. </li>
        <li><strong>Quantum Entanglement in Four-Wave Mixing </strong> <br />
          Undergraduate Research Assistant, <span style="font-weight: bold;">Shaanxi Key Laboratory of Photonics Technology for Information</span>, 2015.6-2016.1, 2016.6-2017.5 <br />
          Advisor: Prof. Yanpeng Zhang. </li>
        <div class="spanner"></div>
      </div>
    </div>

  </div><!-- close page div -->

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <p style="text-align:right;font-size:12px;"> Last updated: Jul. 2025 </p>
    <p style="text-align:right;font-size:12px;"> Template adapted from <a href="https://yumingj.github.io/" target="_blank" style="font-size: 12px;">this website</a> </p>
  </table>

  <p style="display: none;"><script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=-zcFBYdKzlIeLuAqzwHvqJgBI8-m6-8mcFHbmYjjcVk&cl=ffffff&w=a"></script></p>

  <script xml:space="preserve" language="JavaScript">
    hideallbibs();
    hideallabs();
  </script>

</body>

</html>
